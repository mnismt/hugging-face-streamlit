{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_data = pd.read_excel('./data/Third Data.xlsx', sheet_name='Original Sheet (no breakdown)')\n",
    "reviews_data = reviews_data.iloc[1:, :].drop(columns=['Column1']).rename(columns={'Column2': 'URL', 'Column3': 'review_text'}).fillna('').reset_index(drop=True)\n",
    "\n",
    "keywords_data = pd.read_excel('./data/hugging.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 14:01:43.651932: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-21 14:01:43.651967: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from review_text import ReviewText, Sentence\n",
    "from label import get_labels\n",
    "from utils import flatten\n",
    "labels_data, breakdowns_regardless = get_labels()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategorizeReviewTextLabel:\n",
    "  def __init__(self, review_text, label):\n",
    "    # create a Review Text instance\n",
    "    self.review_text = ReviewText(review_text)\n",
    "\n",
    "    self.label = label\n",
    "    self.label_type = self.detect_label_type()\n",
    "    if self.label_type != 0:\n",
    "      self.label_data = labels_data[label]['data']\n",
    "    self._keywords = []\n",
    "    self.FOUND_KEYWORD = False\n",
    "\n",
    "  @property\n",
    "  def keywords(self):\n",
    "    # flatten the keywords & remove duplicate keyword (use set) before return\n",
    "    return list(set(flatten(self._keywords)))\n",
    "\n",
    "  def get_label_data(self, key, flat=False):\n",
    "    data = self.label_data[key]\n",
    "    if flat:\n",
    "      data = flatten(data)\n",
    "      data = [value for value in data if value != '']\n",
    "    return data\n",
    "\n",
    "  def detect_label_type(self):\n",
    "    return labels_data[self.label]['type']\n",
    "\n",
    "  def find_keywords_no_sentiment(self, keywords, change_to_keywords):\n",
    "    results = []\n",
    "    for keywords_index, keywords_present in enumerate(keywords):\n",
    "        for keyword in keywords_present:\n",
    "          if keyword.lower() in self.review_text.text.lower():\n",
    "            corresponding_keyword = change_to_keywords[keywords_index]\n",
    "            results.append(corresponding_keyword)\n",
    "    return results\n",
    "\n",
    "  def add_otherwise_keyword(self):\n",
    "    if 'OTHERWISE' in self.label_data:\n",
    "      # get the keyword\n",
    "      if len(self.label_data['OTHERWISE']) < 2:\n",
    "        otherwise_keyword = self.label_data['OTHERWISE'][0]\n",
    "      else:\n",
    "        otherwise_keyword = self.label_data['OTHERWISE'][self.review_text.sentiment]\n",
    "      self._keywords.append(otherwise_keyword)\n",
    "\n",
    "  def processing(self):\n",
    "    # label_type = 0 => not run\n",
    "    if self.label_type == 0:\n",
    "      return\n",
    "\n",
    "    if self.label_type == 1:\n",
    "      self.processing_type_1()\n",
    "    elif self.label_type == 2:\n",
    "      self.processing_type_2()\n",
    "    elif self.label_type == 3:\n",
    "      self.processing_type_3()\n",
    "    else:\n",
    "      self.processing_type_4()\n",
    "    self.processing_regardless()\n",
    "\n",
    "    # if there are no keyword in the review text, add OTHERWISE keywords\n",
    "    if not self.FOUND_KEYWORD:\n",
    "      self.add_otherwise_keyword()\n",
    "\n",
    "  def processing_type_1(self):\n",
    "    FIND_KEYWORDS = self.get_label_data('FIND KEYWORDS')\n",
    "    CORRESPONDING_KEYWORDS = self.get_label_data('RUN SENTIMENT ANALYSIS')\n",
    "    OPPOSITE_WORDS = None\n",
    "\n",
    "    for find_keywords_index, find_keywords in enumerate(FIND_KEYWORDS):\n",
    "      for find_keyword in find_keywords:\n",
    "        if find_keyword.lower() in self.review_text.text.lower():\n",
    "          # find correspoding keyword\n",
    "          corresponding_keyword = CORRESPONDING_KEYWORDS[find_keywords_index]\n",
    "          # loop through all sentences and find a sentence has that keyword\n",
    "          for sentence in self.review_text.sentences:\n",
    "            if find_keyword.lower() in sentence.text.lower():\n",
    "              self._keywords.append(corresponding_keyword[sentence.sentiment])\n",
    "          self.FOUND_KEYWORD = True\n",
    "\n",
    "    # EXCEPTION: if label is consistency and texture\n",
    "    if self.label == 'consistency and texture':\n",
    "      NO_SENTIMENT_KEYWORDS = self.get_label_data('IF KEYWORDS PRESENT NO SENTIMENT', flat=True)\n",
    "      for no_sentiment_keyword in NO_SENTIMENT_KEYWORDS:\n",
    "        if no_sentiment_keyword in self.review_text.text:\n",
    "          self._keywords.append(no_sentiment_keyword)\n",
    "          self.FOUND_KEYWORD = True\n",
    "    \n",
    "\n",
    "    # handle the exception\n",
    "    if 'BREAKDOWN REGARDLESS OF SENTIMENT' in self.label_data:\n",
    "      for keyword_breakdown_regardless in self.get_label_data('BREAKDOWN REGARDLESS OF SENTIMENT'):\n",
    "        if keyword_breakdown_regardless in self.review_text.text:\n",
    "          self._keywords.append(keyword_breakdown_regardless)\n",
    "    \n",
    "    if 'IF WORDS PRESENT' in self.label_data:\n",
    "      self._keywords.append(self.find_keywords_no_sentiment(self.get_label_data('IF WORDS PRESENT'),\n",
    "                                                      self.get_label_data('CHANGE TO')))\n",
    "      \n",
    "\n",
    "  def processing_type_2(self):\n",
    "    FIND_KEYWORDS = self.label_data['IF KEYWORDS PRESENT NO SENTIMENT']\n",
    "    CORRESPONDING_KEYWORDS = self.label_data['CHANGE TO']\n",
    "    results = self.find_keywords_no_sentiment(FIND_KEYWORDS, CORRESPONDING_KEYWORDS)\n",
    "    if len(results) > 0:\n",
    "      self.FOUND_KEYWORD = True\n",
    "    self._keywords.append(results)\n",
    "\n",
    "    # EXCEPTION: nightly usage\n",
    "    if self.label == 'nightly usage':\n",
    "      if 'overnight' in self.keywords:\n",
    "        if 'night' in self.keywords:\n",
    "          self._keywords = [keyword for keyword in self.keywords if keyword != 'night']\n",
    "\n",
    "  def processing_type_3(self):\n",
    "    if 'IF KEYWORDS PRESENT' not in self.label_data:\n",
    "      FIND_KEYWORDS = self.label_data['RUN SENTIMENT ANALYSIS ON WHOLE REVIEW']\n",
    "      keyword = FIND_KEYWORDS[self.review_text.sentiment]\n",
    "      self._keywords.append(keyword)\n",
    "      self.FOUND_KEYWORD = True\n",
    "\n",
    "    else:\n",
    "      TAKE_FIRST = None\n",
    "      KEYWORD_FOUND = {}\n",
    "\n",
    "      # EXCEPTION: time of usage\n",
    "      if self.label == 'time of usage':\n",
    "        TAKE_FIRST = True\n",
    "\n",
    "      # handle exception\n",
    "      FIND_KEYWORDS = self.label_data['IF KEYWORDS PRESENT']\n",
    "      CORRESPONDING_KEYWORDS = self.label_data['ASSIGN SENTIMENT']\n",
    "      for find_keywords_index, find_keywords in enumerate(FIND_KEYWORDS):\n",
    "        for find_keyword in find_keywords:\n",
    "          if find_keyword.lower() in self.review_text.text.lower():\n",
    "            # find correspoding keyword\n",
    "            if len(CORRESPONDING_KEYWORDS[find_keywords_index]) > 1:\n",
    "              corresponding_keyword = CORRESPONDING_KEYWORDS[find_keywords_index][self.review_text.sentiment]\n",
    "            else:\n",
    "              corresponding_keyword = CORRESPONDING_KEYWORDS[find_keywords_index][0]\n",
    "\n",
    "            # if EXCEPTION: time of usage, try to find first keyword\n",
    "            if TAKE_FIRST:\n",
    "              position_found = self.review_text.text.lower().index(find_keyword.lower())\n",
    "              \n",
    "              if KEYWORD_FOUND == {}:\n",
    "                KEYWORD_FOUND = {'keyword': corresponding_keyword, 'position': position_found}\n",
    "              else:\n",
    "                if position_found < KEYWORD_FOUND['position']:\n",
    "                  KEYWORD_FOUND = {'keyword': corresponding_keyword, 'position': position_found}\n",
    "            else:\n",
    "              self._keywords.append(corresponding_keyword)\n",
    "              self.FOUND_KEYWORD = True\n",
    "\n",
    "      if TAKE_FIRST:\n",
    "        if 'keyword' in KEYWORD_FOUND:\n",
    "          self._keywords.append(KEYWORD_FOUND['keyword'])\n",
    "          self.FOUND_KEYWORD = True\n",
    "      \n",
    "      if 'IF KEYWORDS PRESENT NO SENTIMENT' in self.label_data:\n",
    "        for keywords_index, keywords in enumerate(self.label_data['IF KEYWORDS PRESENT NO SENTIMENT']):\n",
    "          for keyword in keywords:\n",
    "            if keyword.lower() in self.review_text.text.lower():\n",
    "              corresponding_keyword = self.label_data['CHANGE TO'][keywords_index]\n",
    "              self._keywords.append(corresponding_keyword)\n",
    "    \n",
    "  def processing_type_4(self):\n",
    "    CHANGE_TO = self.label_data['CHANGE TO']\n",
    "\n",
    "    for keyword in flatten(CHANGE_TO):\n",
    "      self._keywords.append(keyword)\n",
    "\n",
    "  def processing_regardless(self):\n",
    "    for idx, breakdown in enumerate(breakdowns_regardless):\n",
    "      FIND_KEYWORDS = breakdown['FOR THE WORD']\n",
    "\n",
    "      if idx == 0:\n",
    "        CORRESPONDING_KEYWORDS = breakdown['RUN SENTIMENT ANALYSIS']\n",
    "        OPPOSITE_WORDS = breakdown['OPPOSITE WORDS']\n",
    "        \n",
    "        for find_keywords_index, find_keywords in enumerate(FIND_KEYWORDS):\n",
    "          for find_keyword in find_keywords:\n",
    "            if find_keyword.lower() in self.review_text.text.lower():\n",
    "              # find correspoding keyword\n",
    "              corresponding_keyword = CORRESPONDING_KEYWORDS[find_keywords_index]\n",
    "\n",
    "              # loop through all sentences and find a sentence has that keyword\n",
    "              for sentence in self.review_text.sentences:\n",
    "                if find_keyword.lower() in sentence.text.lower():\n",
    "                  FIND_OPPOSITE = False\n",
    "                  for opposite_word in OPPOSITE_WORDS:\n",
    "                    k = '{0} {1}'.format(opposite_word, find_keyword.lower())\n",
    "                    if k in sentence.text.lower():\n",
    "                      self._keywords.append(corresponding_keyword[0])\n",
    "                      FIND_OPPOSITE = True\n",
    "                  if not FIND_OPPOSITE:\n",
    "                    self._keywords.append(corresponding_keyword[sentence.sentiment])\n",
    "\n",
    "      if idx == 1:\n",
    "        CORRESPONDING_KEYWORDS = breakdown['RERUN CATEGORY']\n",
    "        \n",
    "        temp_label = self.label\n",
    "        temp_label_data = self.label_data\n",
    "        temp_found_keyword = self.FOUND_KEYWORD\n",
    "\n",
    "        for find_keywords_index, find_keywords in enumerate(FIND_KEYWORDS):\n",
    "          for find_keyword in find_keywords:\n",
    "            if find_keyword.lower() in self.review_text.text.lower():\n",
    "              self.label = flatten(CORRESPONDING_KEYWORDS)[find_keywords_index]\n",
    "              self.label_data = labels_data[self.label]['data']\n",
    "              self.FOUND_KEYWORD = False\n",
    "              self.processing_type_1()\n",
    "              if not self.FOUND_KEYWORD:\n",
    "                self.add_otherwise_keyword()\n",
    "        \n",
    "        self.FOUND_KEYWORD = temp_found_keyword\n",
    "        self.label = temp_label\n",
    "        self.label_data = temp_label_data\n",
    "      \n",
    "      if idx == 2:\n",
    "        CORRESPONDING_KEYWORDS = flatten(breakdown['RUN SENTIMENT ANALYSIS'])\n",
    "        \n",
    "        if self.label == 'cleansers and cleansing':\n",
    "          continue\n",
    "\n",
    "        for keyword in flatten(FIND_KEYWORDS):\n",
    "          if keyword in self.review_text.text.lower():\n",
    "            for sentence in self.review_text.sentences:\n",
    "              if keyword.lower() in sentence.text.lower():\n",
    "                self._keywords.append(CORRESPONDING_KEYWORDS[sentence.sentiment])\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no irritation', 'light', 'sensitive skin (positive)', 'creamy']\n"
     ]
    }
   ],
   "source": [
    "review_text = \"\"\"\n",
    "  I read the reviews before day light react I night bought only using hoo creamy stinging\n",
    "  \"\"\"\n",
    "labels = ['sensitive skin (type)']\n",
    "#labels = ['time of usage']\n",
    "\n",
    "for label in labels:\n",
    "  categorized_review_text = CategorizeReviewTextLabel(review_text, label)\n",
    "  categorized_review_text.processing()\n",
    "  print(categorized_review_text.keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:02,  2.22it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# only keep url and review_text\n",
    "results_df = reviews_data.drop(reviews_data.columns[2:], axis=1)\n",
    "reviews_data = reviews_data.iloc[:5, :]\n",
    "\n",
    "for idx, row in tqdm(reviews_data.iterrows()):\n",
    "  url, review_text = row['URL'], row['review_text']\n",
    "  review_labels = [label for label in row[2:] if isinstance(label, str)]\n",
    "\n",
    "  keywords = []\n",
    "  for label in review_labels:\n",
    "    if label in labels_data:\n",
    "      categorized_review_text = CategorizeReviewTextLabel(review_text, label)\n",
    "      categorized_review_text.processing()\n",
    "      keywords.append(categorized_review_text.keywords)\n",
    "\n",
    "  for idx_keyword, keyword in enumerate(list(set(flatten(keywords)))):\n",
    "    keyword_column = 'Keyword {0}'.format(idx_keyword + 1)\n",
    "    if keyword_column not in results_df.columns:\n",
    "      results_df[keyword_column] = ''\n",
    "    results_df.loc[idx, keyword_column] = keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>review_text</th>\n",
       "      <th>Keyword 1</th>\n",
       "      <th>Keyword 2</th>\n",
       "      <th>Keyword 3</th>\n",
       "      <th>Keyword 4</th>\n",
       "      <th>Keyword 5</th>\n",
       "      <th>Keyword 6</th>\n",
       "      <th>Keyword 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.meccabeauty.co.nz/mario-badescu/hy...</td>\n",
       "      <td>Lockdown eyes are super bright. The appearan...</td>\n",
       "      <td>reduced wrinkles</td>\n",
       "      <td>covered/reduced eye circles</td>\n",
       "      <td>shine/bright/lumi/glow/rad</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.meccabeauty.co.nz/mario-badescu/hy...</td>\n",
       "      <td>It feels so soothing around my eyes and help...</td>\n",
       "      <td>reduced wrinkles</td>\n",
       "      <td>cooling/soothing</td>\n",
       "      <td>absorb (positive)</td>\n",
       "      <td>covered/reduced eye circles</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.meccabeauty.co.nz/mario-badescu/hy...</td>\n",
       "      <td>I bought this a couple of weeks ago along wi...</td>\n",
       "      <td>glide makeup (positive)</td>\n",
       "      <td>covered/reduced eye circles</td>\n",
       "      <td>hydrating/moisturising</td>\n",
       "      <td>shine/bright/lumi/glow/rad</td>\n",
       "      <td>rich</td>\n",
       "      <td>weeks (positive)</td>\n",
       "      <td>as/ds/pig/disc (positive)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.meccabeauty.co.nz/mario-badescu/hy...</td>\n",
       "      <td>I brought this a few weeks ago and have used...</td>\n",
       "      <td>weeks (positive)</td>\n",
       "      <td>covered/reduced eye circles</td>\n",
       "      <td>glide makeup (positive)</td>\n",
       "      <td>hydrating/moisturising</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.meccabeauty.co.nz/mario-badescu/hy...</td>\n",
       "      <td>This product is so nice to put on after a bi...</td>\n",
       "      <td>covered/reduced eye circles</td>\n",
       "      <td>night</td>\n",
       "      <td>shine/bright/lumi/glow/rad</td>\n",
       "      <td>days (positive)</td>\n",
       "      <td>calming</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>https://www.meccabeauty.co.nz/kiehls/midnight-...</td>\n",
       "      <td>Bought this a month ago with concerns that I...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>https://www.meccabeauty.co.nz/kiehls/midnight-...</td>\n",
       "      <td>Love it's light texture that goes a long way...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>https://www.meccabeauty.co.nz/kiehls/midnight-...</td>\n",
       "      <td>This cream makes miraculous for my eyes and ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>https://www.meccabeauty.co.nz/kiehls/midnight-...</td>\n",
       "      <td>This is probably my first ever review but I ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>https://www.meccabeauty.co.nz/kiehls/midnight-...</td>\n",
       "      <td>I cannot live without this! Teamed with Midn...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   URL  \\\n",
       "0    https://www.meccabeauty.co.nz/mario-badescu/hy...   \n",
       "1    https://www.meccabeauty.co.nz/mario-badescu/hy...   \n",
       "2    https://www.meccabeauty.co.nz/mario-badescu/hy...   \n",
       "3    https://www.meccabeauty.co.nz/mario-badescu/hy...   \n",
       "4    https://www.meccabeauty.co.nz/mario-badescu/hy...   \n",
       "..                                                 ...   \n",
       "995  https://www.meccabeauty.co.nz/kiehls/midnight-...   \n",
       "996  https://www.meccabeauty.co.nz/kiehls/midnight-...   \n",
       "997  https://www.meccabeauty.co.nz/kiehls/midnight-...   \n",
       "998  https://www.meccabeauty.co.nz/kiehls/midnight-...   \n",
       "999  https://www.meccabeauty.co.nz/kiehls/midnight-...   \n",
       "\n",
       "                                           review_text  \\\n",
       "0      Lockdown eyes are super bright. The appearan...   \n",
       "1      It feels so soothing around my eyes and help...   \n",
       "2      I bought this a couple of weeks ago along wi...   \n",
       "3      I brought this a few weeks ago and have used...   \n",
       "4      This product is so nice to put on after a bi...   \n",
       "..                                                 ...   \n",
       "995    Bought this a month ago with concerns that I...   \n",
       "996    Love it's light texture that goes a long way...   \n",
       "997    This cream makes miraculous for my eyes and ...   \n",
       "998    This is probably my first ever review but I ...   \n",
       "999    I cannot live without this! Teamed with Midn...   \n",
       "\n",
       "                       Keyword 1                    Keyword 2  \\\n",
       "0               reduced wrinkles  covered/reduced eye circles   \n",
       "1               reduced wrinkles             cooling/soothing   \n",
       "2        glide makeup (positive)  covered/reduced eye circles   \n",
       "3               weeks (positive)  covered/reduced eye circles   \n",
       "4    covered/reduced eye circles                        night   \n",
       "..                           ...                          ...   \n",
       "995                                                             \n",
       "996                                                             \n",
       "997                                                             \n",
       "998                                                             \n",
       "999                                                             \n",
       "\n",
       "                      Keyword 3                    Keyword 4 Keyword 5  \\\n",
       "0    shine/bright/lumi/glow/rad                                          \n",
       "1             absorb (positive)  covered/reduced eye circles             \n",
       "2        hydrating/moisturising   shine/bright/lumi/glow/rad      rich   \n",
       "3       glide makeup (positive)       hydrating/moisturising             \n",
       "4    shine/bright/lumi/glow/rad              days (positive)   calming   \n",
       "..                          ...                          ...       ...   \n",
       "995                                                                      \n",
       "996                                                                      \n",
       "997                                                                      \n",
       "998                                                                      \n",
       "999                                                                      \n",
       "\n",
       "            Keyword 6                  Keyword 7  \n",
       "0                                                 \n",
       "1                                                 \n",
       "2    weeks (positive)  as/ds/pig/disc (positive)  \n",
       "3                                                 \n",
       "4                                                 \n",
       "..                ...                        ...  \n",
       "995                                               \n",
       "996                                               \n",
       "997                                               \n",
       "998                                               \n",
       "999                                               \n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('hugging-face-I0JYDplC-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5eea66dcb9a7e933057337a671aaca5ced00053acda169d9eca91d7c3d0306d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
