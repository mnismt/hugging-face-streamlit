{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "reviews_data = pd.read_excel('./data/Third Data.xlsx', sheet_name='Original Sheet (no breakdown)')\n",
    "reviews_data = reviews_data.iloc[1:, :].drop(columns=['Column1']).rename(columns={'Column2': 'URL', 'Column3': 'review_text'}).fillna('').reset_index(drop=True)\n",
    "\n",
    "keywords_data = pd.read_excel('./data/hugging.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-30 15:54:08.699037: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-30 15:54:08.699074: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[nltk_data] Downloading package punkt to /home/gitpod/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "from review_text import ReviewText\n",
    "from utils import flatten, keep_or_delete_label\n",
    "from label import get_labels\n",
    "\n",
    "labels_data, breakdowns_regardless = get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "for lb in labels_data:\n",
    "    if labels_data[lb]['type'] == 3:\n",
    "        print(type(labels_data[lb]['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thick', 'consistency (positive)']\n"
     ]
    }
   ],
   "source": [
    "class CategorizeReviewTextLabel:\n",
    "  def __init__(self, review_text, label):\n",
    "    # create a Review Text instance\n",
    "    self.review_text = ReviewText(review_text)\n",
    "\n",
    "    self.label = label\n",
    "    self.label_type = self.detect_label_type()\n",
    "    if self.label_type != 0:\n",
    "      self.label_data = labels_data[label]['data']\n",
    "    else:\n",
    "      self.label_data = {}\n",
    "    self._keywords = []\n",
    "    self.FOUND_KEYWORD = False\n",
    "\n",
    "  @property\n",
    "  def keywords(self):\n",
    "    # flatten the keywords & remove duplicate keyword (use set) before return\n",
    "    return list(set(flatten(self._keywords)))\n",
    "\n",
    "  def get_label_data(self, key, flat=False):\n",
    "    data = self.label_data[key]\n",
    "    if flat:\n",
    "      data = flatten(data)\n",
    "      data = [value for value in data if value != '']\n",
    "    return data\n",
    "\n",
    "  def detect_label_type(self):\n",
    "    if self.label == None:\n",
    "      return 0\n",
    "    return labels_data[self.label]['type']\n",
    "\n",
    "  def find_keywords_no_sentiment(self, keywords, change_to_keywords):\n",
    "    results = []\n",
    "    for keywords_index, keywords_present in enumerate(keywords):\n",
    "        for keyword in keywords_present:\n",
    "          if keyword.lower() in self.review_text.text.lower():\n",
    "            corresponding_keyword = change_to_keywords[keywords_index]\n",
    "            results.append(corresponding_keyword)\n",
    "    return results\n",
    "\n",
    "  def add_otherwise_keyword(self):\n",
    "    if 'OTHERWISE' in self.label_data:\n",
    "      # get the keyword\n",
    "      if len(self.label_data['OTHERWISE']) < 2:\n",
    "        otherwise_keyword = self.label_data['OTHERWISE'][0]\n",
    "      else:\n",
    "        otherwise_keyword = self.label_data['OTHERWISE'][self.review_text.sentiment]\n",
    "      self._keywords.append(otherwise_keyword)\n",
    "\n",
    "  def processing(self):\n",
    "    # label_type = 0 => not run\n",
    "    if self.label_type == 0:\n",
    "      self.processing_regardless()\n",
    "      return\n",
    "\n",
    "    if self.label_type == 1:\n",
    "      self.processing_type_1()\n",
    "    elif self.label_type == 2:\n",
    "      self.processing_type_2()\n",
    "    elif self.label_type == 3:\n",
    "      self.processing_type_3()\n",
    "    else:\n",
    "      self.processing_type_4()\n",
    "    self.processing_regardless()\n",
    "\n",
    "    # if there are no keyword in the review text, add OTHERWISE keywords\n",
    "    if not self.FOUND_KEYWORD:\n",
    "      self.add_otherwise_keyword()\n",
    "\n",
    "    if self.label == 'consistency and texture':\n",
    "      KEEP_WORDS = flatten(self.get_label_data('UNLESS WORDS PRESENT'))\n",
    "      LABELS_PRESENTS = flatten(self.get_label_data('IF LABELS PRESENT')) + flatten(breakdowns_regardless[0]['IF LABELS PRESENT'])\n",
    "      keep = True\n",
    "\n",
    "      for keyword in LABELS_PRESENTS:\n",
    "        if keyword in self.keywords:\n",
    "          keep = False\n",
    "          break\n",
    "\n",
    "      for word in KEEP_WORDS:\n",
    "        if word in self.review_text.text.lower():\n",
    "          keep = True\n",
    "\n",
    "      if not keep:\n",
    "        try:\n",
    "          self._keywords.remove('consistency (positive)')\n",
    "          self._keywords.remove('consistency (negative)')\n",
    "        except:\n",
    "          pass\n",
    "\n",
    "  def processing_type_1(self, WORD_COMBINATION=False):\n",
    "    FIND_KEYWORDS = self.get_label_data('FIND KEYWORDS')\n",
    "    CORRESPONDING_KEYWORDS = self.get_label_data('RUN SENTIMENT ANALYSIS')\n",
    "    OPPOSITE_WORDS = None\n",
    "\n",
    "    for find_keywords_index, find_keywords in enumerate(FIND_KEYWORDS):\n",
    "      for find_keyword in find_keywords:\n",
    "        if find_keyword.lower() in self.review_text.text.lower():\n",
    "          # find correspoding keyword\n",
    "          corresponding_keyword = CORRESPONDING_KEYWORDS[find_keywords_index]\n",
    "\n",
    "          # loop through all sentences and find a sentence has that keyword\n",
    "          for sentence in self.review_text.sentences:\n",
    "            if find_keyword.lower() in sentence.text.lower():\n",
    "\n",
    "              # EXCEPTION: if label is fragrance and scent\n",
    "              # if self.label == 'fragrance and scent':\n",
    "              #   OPPOSITE_WORDS = self.label_data['OPPOSITE WORDS']\n",
    "              #   for opposite_word in OPPOSITE_WORDS:\n",
    "              #     k = '{0} {1}'.format(\n",
    "              #       opposite_word, find_keyword.lower())\n",
    "              #     if k in sentence.text.lower():\n",
    "              #       self._keywords.append('fragrance free')\n",
    "              \n",
    "              # Exception: eye;circles;dark;darkness;bag;hood\n",
    "              if WORD_COMBINATION:\n",
    "                count = 0\n",
    "                sentence_text = sentence.text.lower()\n",
    "                for keyword in flatten(FIND_KEYWORDS):\n",
    "                  count += keyword in sentence_text\n",
    "                  sentence_text = sentence_text.replace(keyword, '')\n",
    "                  if count >= 2:\n",
    "                    break\n",
    "\n",
    "                if count >= 2:\n",
    "                  self._keywords.append(corresponding_keyword[0])\n",
    "\n",
    "              else:\n",
    "                self._keywords.append(\n",
    "                  corresponding_keyword[sentence.sentiment])\n",
    "\n",
    "              self.FOUND_KEYWORD = True\n",
    "\n",
    "    # EXCEPTION: if label is consistency and texture\n",
    "    if self.label == 'consistency and texture':\n",
    "      NO_SENTIMENT_KEYWORDS = self.get_label_data('IF KEYWORDS PRESENT NO SENTIMENT', flat=True)\n",
    "      for no_sentiment_keyword in NO_SENTIMENT_KEYWORDS:\n",
    "        if no_sentiment_keyword in self.review_text.text.lower():\n",
    "          self._keywords.append(no_sentiment_keyword)\n",
    "          self.FOUND_KEYWORD = True\n",
    "\n",
    "    # handle the exception\n",
    "    if 'BREAKDOWN REGARDLESS OF SENTIMENT' in self.label_data:\n",
    "      for keyword_breakdown_regardless in self.get_label_data('BREAKDOWN REGARDLESS OF SENTIMENT'):\n",
    "        if keyword_breakdown_regardless in self.review_text.text.lower():\n",
    "          self._keywords.append(keyword_breakdown_regardless)\n",
    "    \n",
    "    if 'IF WORDS PRESENT' in self.label_data:\n",
    "      self._keywords.append(self.find_keywords_no_sentiment(self.get_label_data('IF WORDS PRESENT'),\n",
    "                                                      self.get_label_data('CHANGE TO')))\n",
    "      \n",
    "\n",
    "  def processing_type_2(self):\n",
    "    FIND_KEYWORDS = self.label_data['IF KEYWORDS PRESENT NO SENTIMENT']\n",
    "    CORRESPONDING_KEYWORDS = self.label_data['CHANGE TO']\n",
    "    results = self.find_keywords_no_sentiment(FIND_KEYWORDS, CORRESPONDING_KEYWORDS)\n",
    "    if len(results) > 0:\n",
    "      self.FOUND_KEYWORD = True\n",
    "    self._keywords.append(results)\n",
    "\n",
    "    # EXCEPTION: nightly usage\n",
    "    if self.label == 'nightly usage':\n",
    "      if 'overnight' in self.keywords:\n",
    "        if 'night' in self.keywords:\n",
    "          self._keywords = [keyword for keyword in self.keywords if keyword != 'night']\n",
    "\n",
    "  def processing_type_3(self):\n",
    "    if 'IF KEYWORDS PRESENT' not in self.label_data:\n",
    "      FIND_KEYWORDS = self.label_data['RUN SENTIMENT ANALYSIS ON WHOLE REVIEW']\n",
    "      keyword = FIND_KEYWORDS[self.review_text.sentiment]\n",
    "      self._keywords.append(keyword)\n",
    "      self.FOUND_KEYWORD = True\n",
    "\n",
    "    else:\n",
    "      TAKE_FIRST = None\n",
    "      KEYWORD_FOUND = {}\n",
    "\n",
    "      # EXCEPTION: time of usage\n",
    "      if self.label == 'time of usage':\n",
    "        TAKE_FIRST = True\n",
    "\n",
    "      # handle exception\n",
    "      FIND_KEYWORDS = self.label_data['IF KEYWORDS PRESENT']\n",
    "      CORRESPONDING_KEYWORDS = self.label_data['ASSIGN SENTIMENT']\n",
    "      for find_keywords_index, find_keywords in enumerate(FIND_KEYWORDS):\n",
    "        for find_keyword in find_keywords:\n",
    "          if find_keyword.lower() in self.review_text.text.lower():\n",
    "            # find correspoding keyword\n",
    "            if len(CORRESPONDING_KEYWORDS[find_keywords_index]) > 1:\n",
    "              corresponding_keyword = CORRESPONDING_KEYWORDS[find_keywords_index][self.review_text.sentiment]\n",
    "            else:\n",
    "              corresponding_keyword = CORRESPONDING_KEYWORDS[find_keywords_index][0]\n",
    "\n",
    "            # if EXCEPTION: time of usage, try to find first keyword\n",
    "            if TAKE_FIRST:\n",
    "              position_found = self.review_text.text.lower().index(find_keyword.lower())\n",
    "              \n",
    "              if KEYWORD_FOUND == {}:\n",
    "                KEYWORD_FOUND = {'keyword': corresponding_keyword, 'position': position_found}\n",
    "              else:\n",
    "                if position_found < KEYWORD_FOUND['position']:\n",
    "                  KEYWORD_FOUND = {'keyword': corresponding_keyword, 'position': position_found}\n",
    "            else:\n",
    "              self._keywords.append(corresponding_keyword)\n",
    "              self.FOUND_KEYWORD = True\n",
    "\n",
    "      if TAKE_FIRST:\n",
    "        if 'keyword' in KEYWORD_FOUND:\n",
    "          self._keywords.append(KEYWORD_FOUND['keyword'])\n",
    "          self.FOUND_KEYWORD = True\n",
    "      \n",
    "      if 'IF KEYWORDS PRESENT NO SENTIMENT' in self.label_data:\n",
    "        for keywords_index, keywords in enumerate(self.label_data['IF KEYWORDS PRESENT NO SENTIMENT']):\n",
    "          for keyword in keywords:\n",
    "            if keyword.lower() in self.review_text.text.lower():\n",
    "              corresponding_keyword = self.label_data['CHANGE TO'][keywords_index]\n",
    "              self._keywords.append(corresponding_keyword)\n",
    "    \n",
    "  def processing_type_4(self):\n",
    "    CHANGE_TO = self.label_data['CHANGE TO']\n",
    "\n",
    "    for keyword in flatten(CHANGE_TO):\n",
    "      self._keywords.append(keyword)\n",
    "\n",
    "  def processing_regardless(self):\n",
    "    for idx, breakdown in enumerate(breakdowns_regardless):\n",
    "      FIND_KEYWORDS = breakdown['FOR THE WORD']\n",
    "\n",
    "      if idx == 0:\n",
    "        CORRESPONDING_KEYWORDS = breakdown['RUN SENTIMENT ANALYSIS']\n",
    "        OPPOSITE_WORDS = breakdown['OPPOSITE WORDS']\n",
    "        \n",
    "        for find_keywords_index, find_keywords in enumerate(FIND_KEYWORDS):\n",
    "          for find_keyword in find_keywords:\n",
    "            if find_keyword.lower() in self.review_text.text.lower():\n",
    "              # find correspoding keyword\n",
    "              \n",
    "              corresponding_keyword = CORRESPONDING_KEYWORDS[find_keywords_index]\n",
    "\n",
    "              # loop through all sentences and find a sentence has that keyword\n",
    "              for sentence in self.review_text.sentences:\n",
    "                if find_keyword.lower() in sentence.text.lower():\n",
    "                  FIND_OPPOSITE = False\n",
    "                  for opposite_word in OPPOSITE_WORDS:\n",
    "                    k = '{0} {1}'.format(opposite_word, find_keyword.lower())\n",
    "                    if k in sentence.text.lower():\n",
    "                      self._keywords.append(corresponding_keyword[0])\n",
    "                      FIND_OPPOSITE = True\n",
    "                  if not FIND_OPPOSITE:\n",
    "                    self._keywords.append(corresponding_keyword[sentence.sentiment])\n",
    "\n",
    "        if 'IF LABELS PRESENT' in breakdown and 'UNLESS WORDS PRESENT' in breakdown:\n",
    "          KEEP_WORDS = flatten(breakdown['UNLESS WORDS PRESENT'])\n",
    "          LABELS_PRESENTS = flatten(breakdown['IF LABELS PRESENT'])\n",
    "\n",
    "          keep = True\n",
    "          \n",
    "          for keyword in LABELS_PRESENTS:\n",
    "            if keyword in self.keywords:\n",
    "              keep = False\n",
    "              break\n",
    "\n",
    "          for word in KEEP_WORDS:\n",
    "            if word in self.review_text.text.lower():\n",
    "              keep = True\n",
    "\n",
    "          if not keep:\n",
    "            try:\n",
    "              self._keywords.remove('consistency (positive)')\n",
    "              self._keywords.remove('consistency (negative)')\n",
    "            except:\n",
    "              pass\n",
    "\n",
    "\n",
    "      if idx == 1:\n",
    "        CORRESPONDING_KEYWORDS = breakdown['RERUN CATEGORY']\n",
    "        \n",
    "        temp_label = self.label\n",
    "        temp_label_data = self.label_data\n",
    "        temp_found_keyword = self.FOUND_KEYWORD\n",
    "\n",
    "        for find_keywords_index, find_keywords in enumerate(FIND_KEYWORDS):\n",
    "          for find_keyword in find_keywords:\n",
    "            if find_keyword.lower() in self.review_text.text.lower():\n",
    "              self.label = flatten(CORRESPONDING_KEYWORDS)[find_keywords_index]\n",
    "              self.label_data = labels_data[self.label]['data']\n",
    "              self.FOUND_KEYWORD = False\n",
    "              if find_keywords_index == 2:\n",
    "                self.processing_type_1(WORD_COMBINATION=True)\n",
    "              else:\n",
    "                self.processing_type_1()\n",
    "              if not self.FOUND_KEYWORD:\n",
    "                self.add_otherwise_keyword()\n",
    "        \n",
    "        self.FOUND_KEYWORD = temp_found_keyword\n",
    "        self.label = temp_label\n",
    "        self.label_data = temp_label_data\n",
    "      \n",
    "      if idx == 2:\n",
    "        CORRESPONDING_KEYWORDS = flatten(breakdown['RUN SENTIMENT ANALYSIS'])\n",
    "        \n",
    "        if self.label == 'cleansers and cleansing':\n",
    "          continue\n",
    "\n",
    "        for keyword in flatten(FIND_KEYWORDS):\n",
    "          if keyword in self.review_text.text.lower():\n",
    "            for sentence in self.review_text.sentences:\n",
    "              if keyword.lower() in sentence.text.lower():\n",
    "                self._keywords.append(CORRESPONDING_KEYWORDS[sentence.sentiment])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text = \"\"\"\n",
    "  I just purchased this product, and love it already. The mask can be used as a balm during the day, or at night as a mask.\n",
    "  It has no residue taste, and has a nice gloss. Thick and luxurious without it seeping into the mouth.\n",
    "  \"\"\"\n",
    "labels = ['consistency and texture']\n",
    "\n",
    "keywords = []\n",
    "for label in labels:\n",
    "  categorized_review_text = CategorizeReviewTextLabel(review_text, label)\n",
    "  categorized_review_text.processing()\n",
    "  keywords += categorized_review_text.keywords\n",
    "  print(categorized_review_text.keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f6a844c9c046cf9a3251abd9a687e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/929 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eab286a4a7744f3ad694494b9d1e0a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52df3d76471d45859c3428936f0d6851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8165ff97529d4f1f812e99f5b6ff09a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 12:47:51.224576: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-22 12:47:51.224620: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-22 12:47:51.224651: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (gitpodio-templatepython-v7c15bss47f): /proc/driver/nvidia/version does not exist\n",
      "2022-06-22 12:47:51.224928: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99de7a818288409096758f950a7b200b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n",
      "5it [00:16,  3.23s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# only keep url and review_text\n",
    "results_df = reviews_data.drop(reviews_data.columns[2:], axis=1)\n",
    "reviews_data = reviews_data.iloc[:5, :]\n",
    "\n",
    "for idx, row in tqdm(reviews_data.iterrows()):\n",
    "  url, review_text = row['URL'], row['review_text']\n",
    "  review_labels = [label for label in row[2:] if isinstance(label, str)]\n",
    "\n",
    "  if len(review_labels) == 0:\n",
    "    categorized_review_text = CategorizeReviewTextLabel(review_text, None)\n",
    "    categorized_review_text.processing()\n",
    "    keywords.append(categorized_review_text.keywords)\n",
    "\n",
    "  keywords = []\n",
    "  for label in review_labels:\n",
    "    if label in labels_data:\n",
    "      categorized_review_text = CategorizeReviewTextLabel(review_text, label)\n",
    "      categorized_review_text.processing()\n",
    "      keywords.append(categorized_review_text.keywords)\n",
    "\n",
    "  for idx_keyword, keyword in enumerate(list(set(flatten(keywords)))):\n",
    "    keyword_column = 'Keyword {0}'.format(idx_keyword + 1)\n",
    "    if keyword_column not in results_df.columns:\n",
    "      results_df[keyword_column] = ''\n",
    "    results_df.loc[idx, keyword_column] = keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>review_text</th>\n",
       "      <th>Keyword 1</th>\n",
       "      <th>Keyword 2</th>\n",
       "      <th>Keyword 3</th>\n",
       "      <th>Keyword 4</th>\n",
       "      <th>Keyword 5</th>\n",
       "      <th>Keyword 6</th>\n",
       "      <th>Keyword 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.meccabeauty.co.nz/mario-badescu/hy...</td>\n",
       "      <td>Lockdown eyes are super bright. The appearan...</td>\n",
       "      <td>reduced wrinkles</td>\n",
       "      <td>shine/bright/lumi/glow/rad</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.meccabeauty.co.nz/mario-badescu/hy...</td>\n",
       "      <td>It feels so soothing around my eyes and help...</td>\n",
       "      <td>absorb (positive)</td>\n",
       "      <td>reduced wrinkles</td>\n",
       "      <td>cooling/soothing</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.meccabeauty.co.nz/mario-badescu/hy...</td>\n",
       "      <td>I bought this a couple of weeks ago along wi...</td>\n",
       "      <td>shine/bright/lumi/glow/rad</td>\n",
       "      <td>hydrating/moisturising</td>\n",
       "      <td>covered/reduced eye circles</td>\n",
       "      <td>glide makeup (positive)</td>\n",
       "      <td>as/ds/pig/disc (positive)</td>\n",
       "      <td>rich</td>\n",
       "      <td>weeks (positive)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.meccabeauty.co.nz/mario-badescu/hy...</td>\n",
       "      <td>I brought this a few weeks ago and have used...</td>\n",
       "      <td>hydrating/moisturising</td>\n",
       "      <td>glide makeup (positive)</td>\n",
       "      <td>weeks (positive)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.meccabeauty.co.nz/mario-badescu/hy...</td>\n",
       "      <td>This product is so nice to put on after a bi...</td>\n",
       "      <td>night</td>\n",
       "      <td>calming</td>\n",
       "      <td>shine/bright/lumi/glow/rad</td>\n",
       "      <td>days (positive)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>https://www.meccabeauty.co.nz/kiehls/midnight-...</td>\n",
       "      <td>Bought this a month ago with concerns that I...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>https://www.meccabeauty.co.nz/kiehls/midnight-...</td>\n",
       "      <td>Love it's light texture that goes a long way...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>https://www.meccabeauty.co.nz/kiehls/midnight-...</td>\n",
       "      <td>This cream makes miraculous for my eyes and ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>https://www.meccabeauty.co.nz/kiehls/midnight-...</td>\n",
       "      <td>This is probably my first ever review but I ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>https://www.meccabeauty.co.nz/kiehls/midnight-...</td>\n",
       "      <td>I cannot live without this! Teamed with Midn...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   URL  \\\n",
       "0    https://www.meccabeauty.co.nz/mario-badescu/hy...   \n",
       "1    https://www.meccabeauty.co.nz/mario-badescu/hy...   \n",
       "2    https://www.meccabeauty.co.nz/mario-badescu/hy...   \n",
       "3    https://www.meccabeauty.co.nz/mario-badescu/hy...   \n",
       "4    https://www.meccabeauty.co.nz/mario-badescu/hy...   \n",
       "..                                                 ...   \n",
       "995  https://www.meccabeauty.co.nz/kiehls/midnight-...   \n",
       "996  https://www.meccabeauty.co.nz/kiehls/midnight-...   \n",
       "997  https://www.meccabeauty.co.nz/kiehls/midnight-...   \n",
       "998  https://www.meccabeauty.co.nz/kiehls/midnight-...   \n",
       "999  https://www.meccabeauty.co.nz/kiehls/midnight-...   \n",
       "\n",
       "                                           review_text  \\\n",
       "0      Lockdown eyes are super bright. The appearan...   \n",
       "1      It feels so soothing around my eyes and help...   \n",
       "2      I bought this a couple of weeks ago along wi...   \n",
       "3      I brought this a few weeks ago and have used...   \n",
       "4      This product is so nice to put on after a bi...   \n",
       "..                                                 ...   \n",
       "995    Bought this a month ago with concerns that I...   \n",
       "996    Love it's light texture that goes a long way...   \n",
       "997    This cream makes miraculous for my eyes and ...   \n",
       "998    This is probably my first ever review but I ...   \n",
       "999    I cannot live without this! Teamed with Midn...   \n",
       "\n",
       "                      Keyword 1                   Keyword 2  \\\n",
       "0              reduced wrinkles  shine/bright/lumi/glow/rad   \n",
       "1             absorb (positive)            reduced wrinkles   \n",
       "2    shine/bright/lumi/glow/rad      hydrating/moisturising   \n",
       "3        hydrating/moisturising     glide makeup (positive)   \n",
       "4                         night                     calming   \n",
       "..                          ...                         ...   \n",
       "995                                                           \n",
       "996                                                           \n",
       "997                                                           \n",
       "998                                                           \n",
       "999                                                           \n",
       "\n",
       "                       Keyword 3                Keyword 4  \\\n",
       "0                                                           \n",
       "1               cooling/soothing                            \n",
       "2    covered/reduced eye circles  glide makeup (positive)   \n",
       "3               weeks (positive)                            \n",
       "4     shine/bright/lumi/glow/rad          days (positive)   \n",
       "..                           ...                      ...   \n",
       "995                                                         \n",
       "996                                                         \n",
       "997                                                         \n",
       "998                                                         \n",
       "999                                                         \n",
       "\n",
       "                     Keyword 5 Keyword 6         Keyword 7  \n",
       "0                                                           \n",
       "1                                                           \n",
       "2    as/ds/pig/disc (positive)      rich  weeks (positive)  \n",
       "3                                                           \n",
       "4                                                           \n",
       "..                         ...       ...               ...  \n",
       "995                                                         \n",
       "996                                                         \n",
       "997                                                         \n",
       "998                                                         \n",
       "999                                                         \n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('hugging-face-I0JYDplC-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea0738b5ace0f0d1f63905a138a5d0dc65767649e7616d8debbc4c74bb97208d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
